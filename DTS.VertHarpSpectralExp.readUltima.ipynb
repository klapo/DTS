{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and formatting the Ultima data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# netcdf/numpy/xray/stats\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "# OS interaction\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# import plotting\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import kgraph\n",
    "\n",
    "# Customize\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('talk')\n",
    "%matplotlib inline\n",
    "\n",
    "# XML\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Directory Lists\n",
    "\n",
    "# Find host name\n",
    "import socket\n",
    "if socket.gethostname().find('.')>=0:\n",
    "    name=socket.gethostname()\n",
    "else:\n",
    "    name=socket.gethostbyaddr(socket.gethostname())[0]\n",
    "\n",
    "# Determine which machine the script is running on; set up directory names\n",
    "if 'btgmm8' in name:\n",
    "    dirPre = '/Users/karllapo/Desktop/'\n",
    "elif 'klapos' in name:\n",
    "    dirPre = '/Users/karllapo/gdrive/DarkMix/'\n",
    "\n",
    "dirData = dirPre + 'proj/VertHarpExp2017Kloendeel/data/DTS_UltimaVHSRE'\n",
    "dirPrint = dirPre + 'graphics'\n",
    "dirProcessed = dirPre + 'proj/VertHarpExp2017Kloendeel/data/DTS_UltimaVHSRE_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location library for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelLocation(ds):\n",
    "\n",
    "    location = {\n",
    "        ########################\n",
    "        ## Near vertical harp ##\n",
    "        ########################\n",
    "        # Segment 1, up and over ~ 47.3 to 50.8. 2m vertical separation,\n",
    "        # tentatively assign 47.3 to 48.5 as the upward limb.\n",
    "        'vertHarpNear_1': [47.3, 48.5],\n",
    "        # Segment 2, up and over ~ 47.3 to 50.8. 2m vertical separation,\n",
    "        # tentatively assign 50.8 to 49.3 as the downward limb.\n",
    "        'vertHarpNear_2': [49.3, 50.8],\n",
    "        # Segment 3, up and over ~ 51.5 to 54.9. 2m vertical separation,\n",
    "        # tentatively assign 51.5 to 53.0 as the upward limb.\n",
    "        'vertHarpNear_3': [51.5, 53.0],\n",
    "        # Segment 4, up and over ~ 51.5 to 54.9. 2m vertical separation,\n",
    "        # tentatively assign 53.4 to 54.9 as the downward limb.\n",
    "        'vertHarpNear_4': [53.4, 54.9],\n",
    "\n",
    "        #######################\n",
    "        ## Far vertical harp ##\n",
    "        #######################\n",
    "        # Segment 1, up and over ~ 326.2 to 329.75. 2m vertical separation,\n",
    "        # tentatively assign 326.2 to 327.7 as the upward limb.\n",
    "        'vertHarpFar_1': [326.2, 327.7],\n",
    "        # Segment 2, up and over ~ 326.2 to 329.75. 2m vertical separation,\n",
    "        # tentatively assign 329.75 to 328.25 as the downward limb.\n",
    "        'vertHarpFar_2': [328.25, 329.75],\n",
    "        # Segment 3, up and over ~ 330.4 to 333.75. 2m vertical separation,\n",
    "        # tentatively assign 330.4 to 331.9 as the upward limb.\n",
    "        'vertHarpFar_3': [330.4, 331.9],\n",
    "        # Segment 4, up and over ~ 330.4 to 333.75. 2m vertical separation,\n",
    "        # tentatively assign 332.25 to 333.75 as the downward limb.\n",
    "        'vertHarpFar_4': [332.25, 333.75],\n",
    "\n",
    "\n",
    "        ######################\n",
    "        ## Horizontal Array ##\n",
    "        ######################\n",
    "        'Horizontal - 86cm': [245, 294.5],\n",
    "        'Horizontal - 84cm': [192.25, 242],\n",
    "        'Horizontal - 60.5cm': [136, 185.5],\n",
    "        'Horizontal - 56cm': [82.5, 132],\n",
    "\n",
    "        #######################\n",
    "        ## Temperature Baths ##\n",
    "        #######################\n",
    "        'warmBathNear': [29, 33],\n",
    "        'coldBathNear': [17, 22],\n",
    "        'warmBathFar': [346, 351],\n",
    "        'coldBathFar': [357, 362],\n",
    "    }\n",
    "\n",
    "    # Assign location tags\n",
    "    ds.coords['location'] = (('LAF'), [None] * ds.LAF.size)\n",
    "    ds.attrs['locations'] = ';'.join(list(location.keys()))\n",
    "    for l in location:\n",
    "        ds.coords['location'].loc[(ds.LAF > location[l][0]) & (ds.LAF < location[l][-1])] = l\n",
    "\n",
    "    # Assign height values\n",
    "    locationHeights = {\n",
    "        'Horizontal - 86cm': 0.86,\n",
    "        'Horizontal - 84cm': 0.84,\n",
    "        'Horizontal - 60.5cm': 0.605,\n",
    "        'Horizontal - 56cm': 0.56,\n",
    "    }\n",
    "\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " channel 1_20170904234741911.xmlFile 16382 of 16383hannel 1_20170904191131440.xmlFile 1746 of 16383channel 1_20170904192745489.xmlFile 2606 of 16383channel 1_20170904201142931.xmlFile 4930 of 16383channel 1_20170904201448357.xmlFile 5094 of 16383channel 1_20170904204955501.xmlFile 6955 of 16383channel 1_20170904213008696.xmlFile 9089 of 16383channel 1_20170904221318781.xmlFile 11379 of 16383channel 1_20170904224307639.xmlFile 12961 of 16383"
     ]
    }
   ],
   "source": [
    "def readDumbXMLFiles(dumbXMLFile):\n",
    "    with open(dumbXMLFile) as dumb:\n",
    "        doc = xmltodict.parse(dumb.read())\n",
    "    \n",
    "    # Remove all of the bullshit\n",
    "    doc = doc['logs']['log']\n",
    "    \n",
    "    # Extract units/metadata info out of xml dictionary\n",
    "    metaData = {'LAF_beg': float(doc['startIndex']['#text']),\n",
    "                'LAF_end': float(doc['endIndex']['#text']),\n",
    "                'dLAF': float(doc['stepIncrement']['#text']),\n",
    "                'dt_start': pd.to_datetime(doc['startDateTimeIndex'], infer_datetime_format=True),\n",
    "                'dt_end': pd.to_datetime(doc['endDateTimeIndex'], infer_datetime_format=True),\n",
    "                'probe1Temperature': float(doc['customData']['probe1Temperature']['#text']),\n",
    "                'probe2Temperature': float(doc['customData']['probe2Temperature']['#text']),\n",
    "                'fiberOK': int(doc['customData']['fibreStatusOk']),\n",
    "               }\n",
    "\n",
    "    # Extract data\n",
    "    data = doc['logData']['data']\n",
    "\n",
    "    numEntries = np.size(data)\n",
    "    LAF = np.empty(numEntries)\n",
    "    Ps = np.empty_like(LAF)\n",
    "    Pas = np.empty_like(LAF)\n",
    "    temp = np.empty_like(LAF)\n",
    "\n",
    "    for dnum, dlist in enumerate(data):\n",
    "        LAF[dnum], Ps[dnum], Pas[dnum], temp[dnum] = list(map(float, dlist.split(',')))\n",
    "\n",
    "    actualData = pd.DataFrame.from_dict({'LAF': LAF, 'Ps': Ps, 'Pas': Pas, 'temp': temp}).set_index('LAF')\n",
    "    \n",
    "    \n",
    "    return(actualData, metaData)\n",
    "\n",
    "procFlag = True\n",
    "if procFlag:\n",
    "    # List of files to iterate over\n",
    "    os.chdir(dirData)\n",
    "    dirCon = [dC for dC in os.listdir() if 'channel 1' in dC]\n",
    "    nTotal = np.size(dirCon)\n",
    "    ds = None\n",
    "\n",
    "    for nDumb, someDumbFiles in enumerate(dirCon):\n",
    "        if '.xml' in someDumbFiles:\n",
    "            print(\"\\r\", someDumbFiles + 'File ' + str(nDumb) + ' of ' + str(nTotal), end=\"\")\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Read the file\n",
    "        df, meta = readDumbXMLFiles(someDumbFiles)\n",
    "\n",
    "        # Create a temporary xarray Dataset\n",
    "        temp_Dataset = xr.Dataset.from_dataframe(df)\n",
    "        temp_Dataset.coords['time'] = meta['dt_start']\n",
    "        temp_Dataset['probe1Temperature'] = meta['probe1Temperature']\n",
    "        temp_Dataset['probe2Temperature'] = meta['probe2Temperature']\n",
    "        temp_Dataset['fiberStatus'] = meta['fiberOK']\n",
    "\n",
    "        if ds:\n",
    "            ds = xr.concat([ds, temp_Dataset], dim='time')\n",
    "        else:\n",
    "            ds = temp_Dataset\n",
    "\n",
    "        # Chunking/saving to avoid lock-up\n",
    "        if np.mod(nDumb + 1, 1000) == 0 or nDumb == nTotal:\n",
    "            os.chdir(dirProcessed)\n",
    "            numChunk = np.floor_divide(nDumb, 1000)\n",
    "            ds.attrs = {'LAF_beg': meta['LAF_beg'],\n",
    "                        'LAF_end': meta['LAF_end'],\n",
    "                        'dLAF': meta['dLAF']}\n",
    "            ds = labelLocation(ds)\n",
    "            ds.to_netcdf('VHRSE_temp_chunk' + str(numChunk) + '.nc', 'w')\n",
    "            ds.close()\n",
    "            ds = None\n",
    "            os.chdir(dirData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "                                                 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
